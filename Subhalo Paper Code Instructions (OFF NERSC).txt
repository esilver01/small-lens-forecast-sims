0. Introduction


These are the basic instructions and requirements to run the code at https://github.com/esilver01/subhalo-paper-code, used in our paper. It should be possible to replicate all of the results of the paper, though this has not been 100% tested.


One note on the code: the different notebooks may work with various different kernels. Version issues will probably occur, and are probably unavoidable if people are running this code on many different machines. The kernels that we used on NERSC are the following:
NERSC Python: lens_forecast.ipynb, simulations.ipynb, simulations_trunc_SIS.ipynb, figures.ipynb
Tensorflow-2.6.0: shielded_model.ipynb
Tensorflow-2.9.0: shielded_model_small.ipynb


1. Downloads and Installs


“Home Data”: https://drive.google.com/file/d/1-t3jQ0KIVyX9t7C27r3W94m2SEIa-c-D/view?usp=sharing
This file (~1.3 GB) includes the downloaded Williams images, a sample of halos from LensPop for the Collett method in lens_forecast.ipynb, and an array of lens halo masses used for simulating .02”-.15” lenses.


Cosmo DC2: https://data.lsstdesc.org/doc/cosmodc2
Download data: https://data.lsstdesc.org/doc/download
* When downloading at https://data.lsstdesc.org/transfer under Cosmo DC2, choose the “example subset” (42.8 GB)
Install GCR Catalogs and set root directory: https://data.lsstdesc.org/doc/install_gcr


VELA: https://archive.stsci.edu/prepds/vela/
Download data (the images): we use NIRCAM F115W: https://archive.stsci.edu/hlsps/vela/hlsp_vela_jwst_nircam_vela_f115w_v3_sim.tar.gz
The “catalog” (the metadata) is already included in the “Home Data”


The Simulations: Quite large to provide a download link (10GB for each of the 3 simulations)


Drizzled Images: (9.5 GB)
https://drive.google.com/drive/folders/16hmuOtxHuy1YzEJ-FQfCAtoZH_AIqnHJ?usp=sharing
Includes the images from proposals 15923 (in the main folder), as well as 10174 and 10886. These images are only used in testing Models 1a and 1b.


2. Lens Forecast (Requires Cosmo DC2 but not VELA)


Run through lens_forecast.ipynb (NERSC Python kernel)
Options set in first code cell after imports:


Method = Zahid or Collett
Counting = lens_in_source, source_in_lens, or both
Sample size factor = 10 (factor times 100,000 samples are used)
Home directory with data = "/global/cfs/projectdirs/deepsrch/jwst_sims/data/" (default)




3. Simulations (Requires Cosmo DC2 and VELA)


Run through simulations.ipynb (NERSC Python kernel) to generate 20,000 lensed images with no noise (noise is added during training)


Options set in first code cell after imports:
Size = ".5-1.5", ".15-.5", or ".02-.15"
Home directory with data = "/global/cfs/projectdirs/deepsrch/jwst_sims/data/" (default)
Path to VELA images = '/global/cfs/projectdirs/deepsrch/vela' (default)


Remember to set the download path in the last code cell when actually simulating a full set of 20,000 images.


4. Neural Network Training (Requires generated simulations)


Models used in the paper are saved in the model_training folder
To train, run the right notebook:
* 0.5”-1.5” Einstein radius (Model 1): shielded_model.ipynb (tensorflow-2.6.0 kernel)
* 0.15”-0.5” or 0.02”-0.15” Einstein radius (Models 2 and 3): shielded_model_small.ipynb (tensorflow-2.9.0 kernel)


Options set in first code cell after imports:
Home directory = "/global/cfs/projectdirs/deepsrch/jwst_sims/data/" (default)
Simulations directory = ‘/global/cfs/projectdirs/deepsrch/jwst_sims/pristine_bright/’ (default for 0.5”-1.5” simulations)


Both notebooks include sections for validation and testing after the training is complete. Only simulations.ipynb tests Model 1a and 1b on the drizzled HST images.


5. Figures (Requires generated simulations)


Run through the different sections in figures.ipynb (NERSC Python kernel) to generate the rest of the figures used in the paper that aren’t already in the previous notebooks.